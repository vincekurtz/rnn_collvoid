#!/usr/bin/env python

##
# 
#  Load a trained model (generated by train_lstm.py) and
#  use it to predict the motion of an obstacle
#
##

import rospy
from nav_msgs.msg import Odometry
import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.cm as cmx
import matplotlib.colors as colors
from data_container import DataContainer
from network_variables import *

base_dir = "/home/vjkurtz/catkin_ws/src/rnn_collvoid" 

# Store real-time data to access asynchronously
velocity_data = Odometry().twist.twist.linear  # linear x,y,z velocities
position_data = Odometry().pose.pose.position  # x,y,z position

def get_predictions(observations, num_pred):
    """
    Given a sequence of observations, use dropout to generate num_pred unique outputs

    Returns:
        a (num_pred x output_size) np array of outputs
        a list of num_pred updated observation sequences 
    """
    outputs = []

    with tf.Session() as sess:
        # Initialize global variables
        sess.run(tf.global_variables_initializer())

        # Load saved session
        saver = tf.train.Saver()
        saver.restore(sess, "%s/tmp/LSTM_saved_model" % base_dir)

        for i in range(num_pred):
            # This gives a (num_steps x batch_size x output_size), ie (100 x 1 x 4), numpy array. 
            all_pred = sess.run(predicted_outputs, { inputs: observations })
            # We're really only interested in the last prediction: the one for the next step
            next_pred = all_pred[-1][0]   # [deltax, deltay, xdot1, ydot1] 
            
            outputs.append(next_pred)

    return np.asarray(outputs)

def predict_distribution(observations, num_samples):
    """
    Given a sequence of observations, use dropout to generate a gaussian
    distribution over the predictions. 

    Returns a mean vector and covariance matrix based on num_samples
    different possible outputs (obtained with different dropout masks)

    Dropout probabilities are defined in network_variables.py
    """
    
    predictions = []

    with tf.Session() as sess:
        # Initialize global variables
        sess.run(tf.global_variables_initializer())

        # Load saved session
        saver = tf.train.Saver()
        saver.restore(sess, "%s/tmp/LSTM_saved_model" % base_dir)

        for i in range(num_samples):
            # This gives a (num_steps x batch_size x output_size), ie (100 x 1 x 4), numpy array. 
            all_pred = sess.run(predicted_outputs, { inputs: observations })
            # We're really only interested in the last prediction: the one for the next step
            next_pred = all_pred[-1][0]   # [deltax, deltay, xdot1, ydot1] 
            
            predictions.append(next_pred)

    predictions = np.asarray(predictions)  # convert to np array

    # use sample mean and covariance, which are MLE assuming i.i.d. samples
    # from a Gaussian distribution
    mu = np.mean(predictions, axis=0)
    sigma = np.cov(predictions.T)

    return (mu, sigma)


def odom_callback(data):
    global velocity_data
    global position_data
    velocity_data = data.twist.twist.linear
    position_data = data.pose.pose.position

def funnel_test_two():
    """
    Based on an initial observation, propagate an estimate of position forward
    in time. Do this by generating several predictions, estimating an underlying
    distribution, sampling from this distribution (or taking MLE/MMSE/mean?), and using that sample to start
    the process over again.
    """
    
    test_set_file = "%s/data/test_data.csv" % base_dir 
    
    num_samples = 20  # number of samples to use to estimate the underlying distribution
    num_steps = 30   # number of steps to go into the future
    
    # Load initial observations
    test_set = DataContainer(test_set_file)
    obs, _ = test_set.get_next_batch(num_steps=50, batch_size=1, dataset="Test")  # we'll ingore the actual output data in this case

    observations = obs  # make copies 

    # Matplotlib setup to change colors as we move along the trajectory
    color_map = cmx.ScalarMappable(
            norm = colors.Normalize(vmin=0, vmax=num_steps),
            cmap = plt.get_cmap('jet')
            )

    x = 0
    y = 0

    plt.axis([-0.4, 1.2, -.35, 0.05])

    for i in range(num_steps):
        print("Predicting step %s of %s" % (i+1, num_steps))
            
        # Get sample predictions
        predictions = get_predictions(observations, num_samples)

        # Estimate the underlying distribution
        mu = np.mean(predictions, axis=0)   # sample mean
        sigma = np.cov(predictions.T)       # sample covariance

        # Update the observations
        next_pred = mu  #np.random.multivariate_normal(mu, sigma, 1).flatten()
        observations = np.append(observations[1:], [[ next_pred ]], axis=0)
        
        # Add to the plot
        deltax, deltay, dx, dy = np.random.multivariate_normal(mu, sigma, 1000).T   # get a bunch of samples from this distribution
        point_color = color_map.to_rgba(i)
        plt.scatter(x + deltax, y + deltay, color=point_color, alpha=0.2, edgecolors="none")
        
        plt.pause(0.00001)   # allows for realtime plotting

        x += mu[0]  # update list of best predictions for plotting
        y += mu[1]
    
    print("Done! ... plotting ...")
    plt.show()

def get_first_obs():
    """
    Get the initial set of observations. 
    return this initial set of observations, and the initial position
    """
    x = position_data.x
    y = position_data.y

    meas = get_latest_meas(x,y)

    # observations must be a (N, 1, 4) np array
    observations = np.array([[ meas ]])

    return(x,y,observations)

def get_latest_meas(last_x, last_y):
    """
    Return the latest velocity/position measurements: [deltax, deltay, xdot, ydo]
    """
    deltax = position_data.x - last_x
    deltay = position_data.y - last_y
    xdot = velocity_data.x
    ydot = velocity_data.y

    return np.array([deltax, deltay, xdot, ydot])

def main():

    tao = 0.1  # time between samples, in seconds
    buffer_length = 20   # number of observations to predict based on
    num_samples = 10     # number of passes used to approximate the distribution of predicted next positions
    try:
        rospy.init_node('rnn_observer')
        odometer = rospy.Subscriber("/robot_0/base_pose_ground_truth", Odometry, odom_callback)

        # get initial positions and observations
        x, y, observations = get_first_obs()

        rospy.sleep(tao)

        with tf.Session() as sess:  # start up the tensorflow session
            # Initialize global variables
            sess.run(tf.global_variables_initializer())

            # Load saved session
            saver = tf.train.Saver()
            saver.restore(sess, "%s/tmp/LSTM_saved_model" % base_dir)


            while not rospy.is_shutdown():
                # keep track of time
                start_time = rospy.get_time()

                # Get latest measurments
                meas = get_latest_meas(x,y)
                x += meas[0]    # update the latest positions
                y += meas[1]

                # Update the observation buffer
                if len(observations) < buffer_length:
                    # simply add to the buffer
                    observations = np.append(observations, [[ meas ]], axis=0)
                else:
                    # update with replacement
                    observations = np.append(observations[1:], [[ meas ]], axis=0)

                # Generate a prediction
                predictions = []
                for i in range(num_samples):
                    # This gives a (num_steps x batch_size x output_size), ie (100 x 1 x 4), numpy array. 
                    all_pred = sess.run(predicted_outputs, { inputs: observations })
                    # We're really only interested in the last prediction: the one for the next step
                    next_pred = all_pred[-1][0]   # [deltax, deltay, xdot1, ydot1] 
                    predictions.append(next_pred)
                predictions = np.asarray(predictions)  # convert to np array

                # use sample mean and covariance, which are MLE assuming i.i.d. samples
                # from a Gaussian distribution
                mu = np.mean(predictions, axis=0)
                sigma = np.cov(predictions.T)

                # Update the plot - note that this takes a long time when there are too many points!
                deltax, deltay, dx, dy = np.random.multivariate_normal(mu, sigma, 100).T  # get a bunch of sample predictions
                plt.scatter(x + deltax, y + deltay, color="blue", alpha=0.2, edgecolors="none")
                plt.scatter(x,y,color='red')  # ground truth for the last step

                plt.pause(0.0000001)   # updates real-time plot

                # Wait until tao seconds have elapsed
                have_time = False
                while (rospy.get_time() < (start_time + tao)):
                    have_time = True
                if not have_time:
                    # clear axes when we have so many points that it's slowing things down too much
                    plt.cla()  

            plt.show()
            
    except rospy.ROSInterruptException:
        pass

if __name__=="__main__":
    main()
